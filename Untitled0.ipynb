{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngoan22mse23088/GraduationThesis/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbBcuu7ngJjJ",
        "outputId": "d538a765-929f-436e-b9ee-08f59b147823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1jPSejMs_rR5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "# Load the dataset\n",
        "drive.mount('/content/drive')\n",
        "data = []\n",
        "labels = []\n",
        "root_dir = '/content/drive/MyDrive/Training_Set'\n",
        "\n",
        "# Iterate through all subdirectories in the root directory\n",
        "for subdir in os.listdir(root_dir):\n",
        "  # Get the path to the current subdirectory\n",
        "  dataset_path = os.path.join(root_dir, subdir)\n",
        "  for file_name in os.listdir(dataset_path):\n",
        "      # Create the full path to the image\n",
        "      img_path = os.path.join(dataset_path, file_name)\n",
        "\n",
        "      try:\n",
        "          # Read the image\n",
        "          img = cv2.imread(img_path)\n",
        "\n",
        "          # Show the new image\n",
        "          cv2_imshow(img)\n",
        "\n",
        "          # Check if the image is loaded successfully\n",
        "          if img is None:\n",
        "              raise Exception(f\"Error: Unable to read the image at {img_path}\")\n",
        "\n",
        "          # Resize the image\n",
        "          img = cv2.resize(img, (100, 100))\n",
        "\n",
        "          # Flatten and append the image data\n",
        "          data.append(img.flatten())\n",
        "\n",
        "          # Extract the label from the file name\n",
        "          labels.append(file_name.split('.')[0])\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing image: {img_path}\")\n",
        "          print(f\"Exception: {e}\")\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Train the SVM model with probability estimates enabled\n",
        "model = SVC(kernel='linear', C=1.0, probability=True)\n",
        "model.fit(data, encoded_labels)\n",
        "\n",
        "# Predict the label and probability of a new image\n",
        "new_img_path = '/content/drive/MyDrive/test/9999.jpg'\n",
        "\n",
        "try:\n",
        "    # Read and resize the new image\n",
        "    new_img = cv2.imread(new_img_path)\n",
        "\n",
        "    # Show the new image\n",
        "    cv2_imshow(new_img)\n",
        "\n",
        "    new_img = cv2.resize(new_img, (100, 100))\n",
        "\n",
        "    if new_img is None:\n",
        "        raise Exception(f\"Error: Unable to read the new image at {new_img_path}\")\n",
        "\n",
        "    # Flatten the new image\n",
        "    new_img_flat = new_img.flatten()\n",
        "\n",
        "    # Predict class label\n",
        "    predicted_label = model.predict([new_img_flat])[0]\n",
        "\n",
        "    # Predict probability\n",
        "    predicted_probabilities = model.predict_proba([new_img_flat])[0]\n",
        "\n",
        "    # Convert the predicted label back to the original class label\n",
        "    predicted_label_original = label_encoder.inverse_transform([predicted_label])[0]\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Predicted Label: {predicted_label_original}\")\n",
        "    print(f\"Predicted Probabilities: {predicted_probabilities}\")\n",
        "\n",
        "    # Show the new image\n",
        "    cv2_imshow(new_img)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error processing new image: {new_img_path}\")\n",
        "    print(f\"Exception: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: sample for Image Super-Resolution on Set14 - 3x upscaling\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the dataset\n",
        "drive.mount('/content/drive')\n",
        "root_dir = '/content/drive/MyDrive/Training_Set'\n",
        "\n",
        "# Load the images\n",
        "images = []\n",
        "# Iterate through all subdirectories in the root directory\n",
        "for subdir in os.listdir(root_dir):\n",
        "  # Get the path to the current subdirectory\n",
        "  dataset_path = os.path.join(root_dir, subdir)\n",
        "  for file_name in os.listdir(dataset_path):\n",
        "      # Create the full path to the image\n",
        "      img_path = os.path.join(dataset_path, file_name)\n",
        "      image = cv2.imread(img_path)\n",
        "      images.append(image)\n",
        "      # Show the new image\n",
        "      # cv2_imshow(image)\n",
        "\n",
        "# Upscale the images using the model\n",
        "upscaled_images = []\n",
        "for image in images:\n",
        "  upscaled_image = cv2.resize(image, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
        "  upscaled_images.append(upscaled_image)\n",
        "  cv2_imshow(upscaled_image)\n",
        "\n",
        "# Save the upscaled images\n",
        "for i, upscaled_image in enumerate(upscaled_images):\n",
        "  cv2_imshow(image)\n",
        "  output_path = os.path.join(dataset_path, f'upscaled_image_{i+1}.png')\n",
        "  cv2.imwrite(output_path, upscaled_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgxy7pAs0-sw",
        "outputId": "3ee9d199-991f-4f40-8854-14d7697db375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRjY0czbVLFPByXD62KjCE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}